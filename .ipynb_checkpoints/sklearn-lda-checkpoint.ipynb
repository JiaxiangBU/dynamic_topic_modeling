{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp sklearn_lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_df(csv_name):\n",
    "    '''Use jieba, create data frame.'''\n",
    "    df = pd.read_csv(csv_name)\n",
    "    df = df.dropna(subset=['Content'])\n",
    "    df['text'] = df.Content.apply(lambda x: \" \".join(jieba.cut(x)))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\LIJIAX~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.083 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "affirmative = make_df(\"data/affirmative.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Students</th>\n",
       "      <th>Content</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>第1组</td>\n",
       "      <td>正三</td>\n",
       "      <td>慕课将分布于世界各地的最优质的教育资源聚集到一起，让任何有学习愿望的人能够低成本的，通常是免...</td>\n",
       "      <td>慕课 将 分布 于 世界各地 的 最 优质 的 教育资源 聚集 到 一起 ， 让 任何 有 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>第1组</td>\n",
       "      <td>正二</td>\n",
       "      <td>在慕课发展过程中的现阶段，中国最大的慕课平台icourse163的用户人数突破100万,与其...</td>\n",
       "      <td>在 慕课 发展 过程 中 的 现阶段 ， 中国 最大 的 慕课 平台 icourse163 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>第1组</td>\n",
       "      <td>正一</td>\n",
       "      <td>研究发现,在慕课融入的课堂学习中,学习者情感体验丰富,知识技能以及元认知能力得到提升,思想观...</td>\n",
       "      <td>研究 发现 , 在 慕课 融入 的 课堂 学习 中 , 学习者 情感 体验 丰富 , 知识 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>第1组</td>\n",
       "      <td>正三</td>\n",
       "      <td>慕课在保证教育质量的同时，降低提供教育的成本，给社会带来的憧憬。任何人任何时候再任何地方，都...</td>\n",
       "      <td>慕课 在 保证 教育 质量 的 同时 ， 降低 提供 教育 的 成本 ， 给 社会 带来 的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>第1组</td>\n",
       "      <td>正一</td>\n",
       "      <td>对方反一辩友也说是可能出现的欢快气氛，传统课堂集体聆听教师单方面赐予的知识，这难道不是一种容...</td>\n",
       "      <td>对方 反一 辩友 也 说 是 可能 出现 的 欢快 气氛 ， 传统 课堂 集体 聆听 教师 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Group Students                                            Content  \\\n",
       "0   第1组       正三  慕课将分布于世界各地的最优质的教育资源聚集到一起，让任何有学习愿望的人能够低成本的，通常是免...   \n",
       "1   第1组       正二  在慕课发展过程中的现阶段，中国最大的慕课平台icourse163的用户人数突破100万,与其...   \n",
       "2   第1组       正一  研究发现,在慕课融入的课堂学习中,学习者情感体验丰富,知识技能以及元认知能力得到提升,思想观...   \n",
       "3   第1组       正三  慕课在保证教育质量的同时，降低提供教育的成本，给社会带来的憧憬。任何人任何时候再任何地方，都...   \n",
       "4   第1组       正一  对方反一辩友也说是可能出现的欢快气氛，传统课堂集体聆听教师单方面赐予的知识，这难道不是一种容...   \n",
       "\n",
       "                                                text  \n",
       "0  慕课 将 分布 于 世界各地 的 最 优质 的 教育资源 聚集 到 一起 ， 让 任何 有 ...  \n",
       "1  在 慕课 发展 过程 中 的 现阶段 ， 中国 最大 的 慕课 平台 icourse163 ...  \n",
       "2  研究 发现 , 在 慕课 融入 的 课堂 学习 中 , 学习者 情感 体验 丰富 , 知识 ...  \n",
       "3  慕课 在 保证 教育 质量 的 同时 ， 降低 提供 教育 的 成本 ， 给 社会 带来 的...  \n",
       "4  对方 反一 辩友 也 说 是 可能 出现 的 欢快 气氛 ， 传统 课堂 集体 聆听 教师 ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affirmative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = make_df(\"data/negative.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Students</th>\n",
       "      <th>Content</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>第1组</td>\n",
       "      <td>反一</td>\n",
       "      <td>通俗地说，慕课是大规模的网络开放课程。1.传统课堂中可能出现的欢快的气氛，慕课没有；2.传统...</td>\n",
       "      <td>通俗 地说 ， 慕课 是 大规模 的 网络 开放 课程 。 1 . 传统 课堂 中 可能 出...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>第1组</td>\n",
       "      <td>反一</td>\n",
       "      <td>通俗地说，慕课是大规模的网络开放课程。我方观点为，慕课不能代替传统课堂1.传统课堂中可能出现...</td>\n",
       "      <td>通俗 地说 ， 慕课 是 大规模 的 网络 开放 课程 。 我方 观点 为 ， 慕课 不能 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>第1组</td>\n",
       "      <td>反一</td>\n",
       "      <td>正一观点中有这样一句话“相比在线交流,学习者偏好面对面的交流讨论”这不正是传统课堂所能给予的吗</td>\n",
       "      <td>正一 观点 中有 这样 一句 话 “ 相比 在线 交流 , 学习者 偏好 面对面 的 交流 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>第1组</td>\n",
       "      <td>反一</td>\n",
       "      <td>正二给出的数字中，说明不了慕课的替代性，毕竟中国学生庞大的基数在这。</td>\n",
       "      <td>正二 给出 的 数字 中 ， 说明 不了 慕课 的 替代性 ， 毕竟 中国 学生 庞大 的 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>第1组</td>\n",
       "      <td>反一</td>\n",
       "      <td>正一说的独立思考问题，传统课堂的弹性较大，课堂设计掌握在老师学生手中，可以做到因材施教，针对...</td>\n",
       "      <td>正一说 的 独立思考 问题 ， 传统 课堂 的 弹性 较大 ， 课堂 设计 掌握 在 老师 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Group Students                                            Content  \\\n",
       "0   第1组       反一  通俗地说，慕课是大规模的网络开放课程。1.传统课堂中可能出现的欢快的气氛，慕课没有；2.传统...   \n",
       "1   第1组       反一  通俗地说，慕课是大规模的网络开放课程。我方观点为，慕课不能代替传统课堂1.传统课堂中可能出现...   \n",
       "2   第1组       反一    正一观点中有这样一句话“相比在线交流,学习者偏好面对面的交流讨论”这不正是传统课堂所能给予的吗   \n",
       "3   第1组       反一                 正二给出的数字中，说明不了慕课的替代性，毕竟中国学生庞大的基数在这。   \n",
       "4   第1组       反一  正一说的独立思考问题，传统课堂的弹性较大，课堂设计掌握在老师学生手中，可以做到因材施教，针对...   \n",
       "\n",
       "                                                text  \n",
       "0  通俗 地说 ， 慕课 是 大规模 的 网络 开放 课程 。 1 . 传统 课堂 中 可能 出...  \n",
       "1  通俗 地说 ， 慕课 是 大规模 的 网络 开放 课程 。 我方 观点 为 ， 慕课 不能 ...  \n",
       "2  正一 观点 中有 这样 一句 话 “ 相比 在线 交流 , 学习者 偏好 面对面 的 交流 ...  \n",
       "3  正二 给出 的 数字 中 ， 说明 不了 慕课 的 替代性 ， 毕竟 中国 学生 庞大 的 ...  \n",
       "4  正一说 的 独立思考 问题 ， 传统 课堂 的 弹性 较大 ， 课堂 设计 掌握 在 老师 ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pyLDAvis \n",
    "import pyLDAvis.sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import jieba\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "def chinese_word_cut(mytext):\n",
    "    return \" \".join(jieba.cut(mytext))\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_custom_stopwords(stop_words_file, encoding = 'utf-8'):\n",
    "    with open(stop_words_file, encoding = encoding) as f:\n",
    "        stopwords = f.read()\n",
    "    stopwords_list = stopwords.split('\\n')\n",
    "    custom_stopwords_list = [i for i in stopwords_list]\n",
    "    return custom_stopwords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = get_custom_stopwords(\"data/stopwords.txt\", encoding='utf-8') # HIT停用词词典\n",
    "max_df = 0.9 # 在超过这一比例的文档中出现的关键词（过于平凡），去除掉。\n",
    "min_df = 5 # 在低于这一数量的文档中出现的关键词（过于独特），去除掉。\n",
    "n_features = 1000 # 最大提取特征数量\n",
    "n_top_words = 20 # 显示主题下关键词的时候，显示多少个\n",
    "col_content = \"text\" # 说明其中的文本信息所在列名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def lda_on_chinese_articles_with_param(df, n_topics, \n",
    "                            col_content, \n",
    "                            stopwords, \n",
    "                            n_features, \n",
    "                            max_df, \n",
    "                            min_df,\n",
    "                            n_top_words):\n",
    "    articles_cutted = df[col_content].apply(chinese_word_cut)\n",
    "    vect = CountVectorizer(max_df = max_df, \n",
    "                       min_df = min_df, \n",
    "                       token_pattern=u'(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b', \n",
    "                       stop_words=frozenset(stopwords))\n",
    "    tf = vect.fit_transform(articles_cutted)\n",
    "    lda = LatentDirichletAllocation(n_components=n_topics, max_iter=50,\n",
    "                                    learning_method='online',\n",
    "                                    learning_offset=50,\n",
    "                                    random_state=0)\n",
    "    lda.fit(tf)\n",
    "    print_top_words(lda, vect.get_feature_names(), n_top_words)\n",
    "    return lda, tf, vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def lda_on_chinese_articles(df, n_topics):\n",
    "    return lda_on_chinese_articles_with_param(df, n_topics, \n",
    "                            col_content = col_content, \n",
    "                            stopwords = stopwords, \n",
    "                            n_features = n_features, \n",
    "                            max_df = max_df, \n",
    "                            min_df = min_df,\n",
    "                            n_top_words = n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\install\\miniconda\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['lex', '①①', '①②', '①③', '①④', '①⑤', '①⑥', '①⑦', '①⑧', '①⑨', '①ａ', '①ｂ', '①ｃ', '①ｄ', '①ｅ', '①ｆ', '①ｇ', '①ｈ', '①ｉ', '①ｏ', '②①', '②②', '②③', '②④', '②⑤', '②⑥', '②⑦', '②⑧', '②⑩', '②ａ', '②ｂ', '②ｄ', '②ｅ', '②ｆ', '②ｇ', '②ｈ', '②ｉ', '②ｊ', '③①', '③⑩', '③ａ', '③ｂ', '③ｃ', '③ｄ', '③ｅ', '③ｆ', '③ｇ', '③ｈ', '④ａ', '④ｂ', '④ｃ', '④ｄ', '④ｅ', '⑤ａ', '⑤ｂ', '⑤ｄ', '⑤ｅ', '⑤ｆ', 'ｌｉ', 'ｎｇ', 'ｚｘｆｉｔｌ'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "学习 学生 交流 课程 学习者 视频 时间 网络 讨论 进行 教师 课堂 自主 知识 教学 兴趣 实现 促进 合作 高等教育\n",
      "Topic #1:\n",
      "教育 发展 传统 大学 已经 取代 我国 不能 社会 课堂 问题 不是 认为 时代 现在 目前 技术 国家 高等教育 高校\n",
      "Topic #2:\n",
      "学生 课堂 传统 学习 教师 老师 教学 进行 方式 过程 视频 知识 课程 需要 一种 不是 问题 时间 没有 模式\n"
     ]
    }
   ],
   "source": [
    "lda, tf, vect = lda_on_chinese_articles(df = affirmative, n_topics = 3)\n",
    "pyLDAvis.sklearn.prepare(lda, tf, vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "TypeError: __init__() got an unexpected keyword argument 'n_topics'\n",
    "```\n",
    "\n",
    "一般出现这种问题都是程序中字母写错、漏写之类的问题\n",
    "\n",
    "————————————————\n",
    "\n",
    "版权声明：本文为CSDN博主「zhuimengshaonian66」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。\n",
    "原文链接：https://blog.csdn.net/zhuimengshaonian66/article/details/81700959\n",
    "\n",
    "`n_components` 参数名称修改了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda, tf, vect = lda_on_chinese_articles(df = negative, n_topics = 3)\n",
    "pyLDAvis.sklearn.prepare(lda, tf, vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(lda, tf, vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考 https://github.com/bmabey/pyLDAvis/issues/132\n",
    "    \n",
    "```python\n",
    "D:\\install\\miniconda\\lib\\site-packages\\pyLDAvis\\_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
    "of pandas will change to not sort by default.\n",
    "\n",
    "To accept the future behavior, pass 'sort=False'.\n",
    "\n",
    "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
    "\n",
    "  return pd.concat([default_term_info] + list(topic_dfs))\n",
    "```\n",
    "\n",
    "重新安装后依然没有解决。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyldavis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(\"model/sklearn-lda.pkl\", 'wb') as fp:\n",
    "    pkl.dump(lda, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"model/sklearn-lda.pkl\", 'rb') as fp:\n",
    "    model0 = pkl.load(fp)\n",
    "    print(model0.__class__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
