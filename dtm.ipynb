{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dynamic_topic_modeling.sklearn_lda import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\LIJIAX~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.909 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "affirmative = make_df(\"data/affirmative.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Students</th>\n",
       "      <th>Content</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>第1组</td>\n",
       "      <td>正三</td>\n",
       "      <td>慕课将分布于世界各地的最优质的教育资源聚集到一起，让任何有学习愿望的人能够低成本的，通常是免...</td>\n",
       "      <td>慕课 将 分布 于 世界各地 的 最 优质 的 教育资源 聚集 到 一起 ， 让 任何 有 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>第1组</td>\n",
       "      <td>正二</td>\n",
       "      <td>在慕课发展过程中的现阶段，中国最大的慕课平台icourse163的用户人数突破100万,与其...</td>\n",
       "      <td>在 慕课 发展 过程 中 的 现阶段 ， 中国 最大 的 慕课 平台 icourse163 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>第1组</td>\n",
       "      <td>正一</td>\n",
       "      <td>研究发现,在慕课融入的课堂学习中,学习者情感体验丰富,知识技能以及元认知能力得到提升,思想观...</td>\n",
       "      <td>研究 发现 , 在 慕课 融入 的 课堂 学习 中 , 学习者 情感 体验 丰富 , 知识 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>第1组</td>\n",
       "      <td>正三</td>\n",
       "      <td>慕课在保证教育质量的同时，降低提供教育的成本，给社会带来的憧憬。任何人任何时候再任何地方，都...</td>\n",
       "      <td>慕课 在 保证 教育 质量 的 同时 ， 降低 提供 教育 的 成本 ， 给 社会 带来 的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>第1组</td>\n",
       "      <td>正一</td>\n",
       "      <td>对方反一辩友也说是可能出现的欢快气氛，传统课堂集体聆听教师单方面赐予的知识，这难道不是一种容...</td>\n",
       "      <td>对方 反一 辩友 也 说 是 可能 出现 的 欢快 气氛 ， 传统 课堂 集体 聆听 教师 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Group Students                                            Content  \\\n",
       "0   第1组       正三  慕课将分布于世界各地的最优质的教育资源聚集到一起，让任何有学习愿望的人能够低成本的，通常是免...   \n",
       "1   第1组       正二  在慕课发展过程中的现阶段，中国最大的慕课平台icourse163的用户人数突破100万,与其...   \n",
       "2   第1组       正一  研究发现,在慕课融入的课堂学习中,学习者情感体验丰富,知识技能以及元认知能力得到提升,思想观...   \n",
       "3   第1组       正三  慕课在保证教育质量的同时，降低提供教育的成本，给社会带来的憧憬。任何人任何时候再任何地方，都...   \n",
       "4   第1组       正一  对方反一辩友也说是可能出现的欢快气氛，传统课堂集体聆听教师单方面赐予的知识，这难道不是一种容...   \n",
       "\n",
       "                                                text  \n",
       "0  慕课 将 分布 于 世界各地 的 最 优质 的 教育资源 聚集 到 一起 ， 让 任何 有 ...  \n",
       "1  在 慕课 发展 过程 中 的 现阶段 ， 中国 最大 的 慕课 平台 icourse163 ...  \n",
       "2  研究 发现 , 在 慕课 融入 的 课堂 学习 中 , 学习者 情感 体验 丰富 , 知识 ...  \n",
       "3  慕课 在 保证 教育 质量 的 同时 ， 降低 提供 教育 的 成本 ， 给 社会 带来 的...  \n",
       "4  对方 反一 辩友 也 说 是 可能 出现 的 欢快 气氛 ， 传统 课堂 集体 聆听 教师 ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affirmative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_slices = affirmative['Group'] \\\n",
    "    .value_counts() \\\n",
    "    .reindex(affirmative['Group'].unique().tolist()) \\\n",
    "    .tolist()\n",
    "# regex https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.replace.html\n",
    "# reindex https://blog.csdn.net/songyunli1111/article/details/78953841"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[67, 135, 50, 53, 50, 47, 53, 68, 63, 31]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = get_custom_stopwords(\"data/stopwords.txt\", encoding='utf-8') # HIT停用词词典\n",
    "max_df = 0.9 # 在超过这一比例的文档中出现的关键词（过于平凡），去除掉。\n",
    "min_df = 5 # 在低于这一数量的文档中出现的关键词（过于独特），去除掉。\n",
    "n_features = 1000 # 最大提取特征数量\n",
    "n_top_words = 20 # 显示主题下关键词的时候，显示多少个\n",
    "col_content = \"text\" # 说明其中的文本信息所在列名称"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_documents = affirmative['text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考 https://blog.csdn.net/kwame211/article/details/78963517\n",
    "import jieba\n",
    "docs = [[word for word in jieba.cut(document, cut_all=True)] for document in raw_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\install\\miniconda\\lib\\site-packages\\scipy\\sparse\\sparsetools.py:21: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  _deprecated()\n",
      "D:\\install\\miniconda\\lib\\site-packages\\gensim\\models\\doc2vec.py:73: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import namedtuple, defaultdict, Iterable\n"
     ]
    }
   ],
   "source": [
    "# 参考 https://radimrehurek.com/gensim/auto_examples/tutorials/run_lda.html#sphx-glr-auto-examples-tutorials-run-lda-py\n",
    "from gensim.corpora import Dictionary\n",
    "# Create a dictionary representation of the documents.\n",
    "dictionary = Dictionary(docs)\n",
    "\n",
    "# Filter out words that occur less than 5 documents, or more than 90% of the documents.\n",
    "dictionary.filter_extremes(no_below=5, no_above=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "TypeError: doc2bow expects an array of unicode tokens on input, not a single string\n",
    "```\n",
    "\n",
    "- [x] list 化 https://blog.csdn.net/cg_amaz1ng/article/details/79567583"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [dictionary.doc2bow(doc) for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 1060\n",
      "Number of documents: 617\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary))\n",
    "print('Number of documents: %d' % len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.wrappers import DtmModel\n",
    "\n",
    "# Set training parameters.\n",
    "num_topics = 8\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "# 参考 https://radimrehurek.com/gensim/models/wrappers/dtmmodel.html\n",
    "# dtm-win64.exe\n",
    "\n",
    "model = DtmModel('refs/dtm-win64.exe', corpus=corpus, id2word=id2word, num_topics = num_topics,\n",
    "                 time_slices=series_slices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# cite https://github.com/GSukr/dtmvisual\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_topic(timespans, num_topics, model, num_words = 10):\n",
    "    \n",
    "    \"\"\"\n",
    "    :param timespans: number od timespans/periods\n",
    "    :param num_topics: number of topics\n",
    "    :param model: DTM trained model\n",
    "    :param num_words: number of words to display for the topicid at the time period\n",
    "    :return: Dataframe with corresponding weight for each top word in each topic of each period\n",
    "    \"\"\"\n",
    "    topicId, period, weight, word = [], [], [], []\n",
    "    for t in range(timespans):\n",
    "        for s in range (num_topics):\n",
    "            topics = model.show_topic(topicid=s, time=t, topn=num_words)\n",
    "            # num_words : int, optional\n",
    "            #    DEPRECATED PARAMETER, use `topn` instead.\n",
    "            for i, (w, word_) in enumerate(topics):\n",
    "                topicId.append(s)\n",
    "                period.append(t)\n",
    "                weight.append(w)\n",
    "                word.append(word_)\n",
    "    return pd.DataFrame(list(zip(topicId, period, weight, word)), columns = ['topicId', 'period', 'word', 'weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = display_topic(timespans=len(series_slices), num_topics=num_topics, model=model, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topicId</th>\n",
       "      <th>period</th>\n",
       "      <th>word</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.047107</td>\n",
       "      <td>课</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046671</td>\n",
       "      <td>慕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.029236</td>\n",
       "      <td>发展</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.024442</td>\n",
       "      <td>教育</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022667</td>\n",
       "      <td>是</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topicId  period      word weight\n",
       "0        0       0  0.047107      课\n",
       "1        0       0  0.046671      慕\n",
       "2        0       0  0.029236     发展\n",
       "3        0       0  0.024442     教育\n",
       "4        0       0  0.022667      是"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.to_csv(\"output/model_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考 https://github.com/le-hoang-nhan/dynamic-topic-modeling\n",
    "# print(model.show_topic(topicid=1, time=0, topn=10))\n",
    "# print(model.show_topic(topicid=2, time=0, topn=10))\n",
    "# **第一次**执行很慢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](figure/word_evolution.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc = 0, model.gamma_[doc] [1.88394876e-04 6.97243420e-01 1.88394876e-04 1.88394876e-04\n",
      " 3.01626211e-01 1.88394876e-04 1.88394876e-04 1.88394876e-04]\n"
     ]
    }
   ],
   "source": [
    "#Distance between documents: compare the documents across different time-frames and see how similar they are topic-wise\n",
    "#considering document 0\n",
    "doc = 0\n",
    "print(\"doc = 0, model.gamma_[doc]\",model.gamma_[doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9376350531229791"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The distance between documents based on their topic distribution: lower, more related\n",
    "\n",
    "from gensim.matutils import hellinger\n",
    "# considering document 4 and 5\n",
    "doc1 = 4\n",
    "doc2 = 5\n",
    "hellinger(model.gamma_[doc1], model.gamma_[doc2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pyLDAvis\n",
    "\n",
    "# doc_topic, topic_term, doc_lengths, term_frequency, vocab = model.dtm_vis(time=0, corpus=corpus)\n",
    "# vis_wrapper = pyLDAvis.prepare(topic_term_dists=topic_term, doc_topic_dists=doc_topic, doc_lengths=doc_lengths, vocab=vocab, term_frequency=term_frequency)\n",
    "# pyLDAvis.display(vis_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(\"model/dtm.pkl\", 'wb') as fp:\n",
    "    pkl.dump(model, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'gensim.models.wrappers.dtmmodel.DtmModel'>\n"
     ]
    }
   ],
   "source": [
    "with open(\"model/dtm.pkl\", 'rb') as fp:\n",
    "    model0 = pkl.load(fp)\n",
    "    print(model0.__class__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
